---
title: "563project"
author: "Yan Liu"
date: "11/9/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

Read data
```{r}
library(tidyverse)

data_whole<-read_csv("diabetes.csv")

```

Split data
Split the data into a training (70% of the data) and test set (30% of the data)
```{r}
library(caret)
library(rsample)
set.seed(14)
index <- initial_split(data_whole,
                       prop = 0.7)
train <- training(index)
test <- testing(index)
```

Data Plots

```{r}
library(corrplot)
res <- cor(data_whole)

#Plot the correlation matrix values by cluster
corrplot(res, type = "upper", order = "hclust",
         tl.col = "black", tl.cex = 0.5)

table(data_whole$Outcome)
mean(data_whole$Outcome)#NIR

table(data_whole$Outcome)/nrow(data_whole)
```


```{r,fig1, fig.height = 20, fig.width = 20}
library(PerformanceAnalytics)
chart.Correlation(data_whole, histogram = TRUE, method = "pearson")
```

```{r}
train <- train %>% 
  mutate(Outcome = as.factor(Outcome))
test <- test %>% 
  mutate(Outcome = as.factor(Outcome))
glm<- glm(Outcome~.,train,family="binomial")
summary(glm)
par(mfrow=c(2,2))
plot(glm)
car::vif(glm)# a VIF value larger than 5 or 10 indicates a problematic amount of multicollinearity, No multicollinearity

glm_prob <- predict(glm, test,type = "response")
glm_pred <- rep(0, length(glm_prob))
glm_pred[glm_prob > 0.5] <- 1
error_glm<-mean(glm_pred != test$Outcome)

confusionMatrix(data = test$Outcome, reference = factor(glm_pred))

library(pROC)
library(ggplot2)
roccurve <- roc(response = test$Outcome, predictor = glm_prob)
ggroc(roccurve, legacy.axes = TRUE, lwd=2) +theme_bw(base_size = 18)
auc(roccurve)
#yhat_glm<-predict(glm,test)
#RMSE_glm<-sqrt(mean((test$shares - exp(yhat_lm))^2))
```

```{r}
#backward selection after log transformation
library(leaps)
backward<- regsubsets(Outcome~., train, nvmax = 9, method = "backward")
backward_summary<-summary(backward)

#backward_summary[["which"]][size, ]
par(mfrow=c(1,3))
plot(backward_summary$cp, xlab = "Size", ylab = "backward Cp", type = "l")
plot(backward_summary$bic, xlab = "Size", ylab = "backward bic", type = "l")
plot(backward_summary$adjr2, xlab = "Size", ylab = "backward adjR2", type = "l")

coef(backward, which.min(backward_summary$cp))
coef(backward, which.max(backward_summary$adjr2))

#get best subset of the specified size with min cp.
# Create test model matrix, predcition, test error
sub <- backward_summary$which[which.min(backward_summary$cp), ]
test_model <- model.matrix(Outcome~ ., data = test)
test_back <- test_model[, sub]

back_odds<-exp(test_back %*% coef(backward, which.min(backward_summary$cp)))


back_prob<-back_odds/(1+back_odds)

back_pred <- rep(0, length(back_prob))
back_pred[back_prob > 0.5] <- 1
error_back<-mean(back_pred != test$Outcome)


```

```{r}
library(rpart)
library(rpart.plot)
tree_class <- rpart(
  Outcome ~ .,
  data = train,
  method = 'class',
  parms = list(split = "information"),
  control = rpart.control(
    xval = 10,
    minbucket = 2,
    cp = 0
  )
)
printcp(tree_class)
cp <- tree_class$cptable
tree_class_final <- prune(tree_class, cp = cp[4,1])#used minimum
rpart.plot(tree_class_final)

# test error rate using min cp
tree_pred <- predict(tree_class_final, newdata=test, type = "class")
klaR::errormatrix(true = test$Outcome, predicted = tree_pred, relative = TRUE)
```

```{r}

